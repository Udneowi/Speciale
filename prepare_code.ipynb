{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterize time (in seconds) onto the unit circle \n",
    "def time_to_circle(time):\n",
    "    seconds_per_day = 60*60*24\n",
    "    cos_time = np.cos(2*np.pi*time/seconds_per_day)\n",
    "    sin_time = np.sin(2*np.pi*time/seconds_per_day)\n",
    "    return cos_time, sin_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Unix time onto the unit circle (time of day) and the week day\n",
    "def time_stamp(times):\n",
    "    datetimes = np.array([datetime.fromtimestamp(time[1]) for time in times])\n",
    "    week_day = [time.weekday() for time in datetimes]\n",
    "    times = np.array([time.second + time.minute*60 + time.hour*60*60 for time in datetimes])\n",
    "    time_circle = time_to_circle(times)\n",
    "    return time_circle, week_day\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates list of zeros and ones where ones means that it is the first time the location is seen.\n",
    "def explore(path):\n",
    "    seen = set()\n",
    "    explore_path = []\n",
    "    for place in path:\n",
    "        if place in seen:\n",
    "            explore_path.append(0)\n",
    "        else:\n",
    "            explore_path.append(1)\n",
    "            seen.add(place)\n",
    "    return explore_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all the data in saved files such that 1 file contains all the information for one person.\n",
    "# A file for test, train and all of the data is created.\n",
    "# In total it created a file containing the matrix: [path,time_cos,time_sin,week_day,explore_path,person_ID]\n",
    "# It also relables the location id in path such that the amount if descending the higher the id.\n",
    "def prepare_data(peps):\n",
    "    tmp_max = 0\n",
    "    for pep in peps:\n",
    "        try:\n",
    "            with open(f\"Data/{pep}/final_series.json\") as json_file:\n",
    "                data_path = json.load(json_file)\n",
    "            with open(f\"Data/{pep}/timestamps.json\") as json_file:\n",
    "                time = json.load(json_file)\n",
    "\n",
    "            [time_cos,time_sin], week_day = time_stamp(time)\n",
    "\n",
    "            data_path = [path[-1] for path in data_path]\n",
    "\n",
    "            \n",
    "\n",
    "            explore_path = explore(data_path)\n",
    "            person_list = [pep for _ in range(len(explore_path))]\n",
    "            \n",
    "            data = np.array([data_path,time_cos,time_sin,week_day,explore_path,person_list])\n",
    "            \n",
    "            frac = int(data.shape[1]*0.90)\n",
    "            data_train = data[:,:frac].copy()\n",
    "            data_test = data[:,frac:].copy()\n",
    "            \n",
    "            np.save(f\"Data/{pep}/prepared_data_train.npy\",data_train)\n",
    "            np.save(f\"Data/{pep}/prepared_data_test.npy\",data_test)\n",
    "            np.save(f\"Data/{pep}/prepared_data_all.npy\",data)\n",
    "            \n",
    "            \n",
    "            counter = Counter(data_train[0,:])\n",
    "            counter_all = Counter(data[0,:])\n",
    "            ranks = {rank[0]:i for i,rank in enumerate(counter.most_common())}\n",
    "            ranks_all = {rank[0]:i for i,rank in enumerate(counter_all.most_common())}\n",
    "            data_train_relabeled = [ranks[loc] for loc in data_train[0,:]]\n",
    "            data_test_relabeled = [ranks[loc] if loc in ranks else 900 for loc in data_test[0,:] ]\n",
    "            data_all_relabeled = [ranks_all[loc] for loc in data[0,:]]\n",
    "            data_train[0,:] = data_train_relabeled\n",
    "            data_test[0,:] = data_test_relabeled\n",
    "            data[0,:] = data_all_relabeled\n",
    "            np.save(f\"Data/{pep}/prepared_data_train_relabeled.npy\",data_train)\n",
    "            np.save(f\"Data/{pep}/prepared_data_test_relabeled.npy\",data_test)\n",
    "            np.save(f\"Data/{pep}/prepared_data_all_relabeled.npy\",data)\n",
    "            df_ranks = pd.DataFrame(list(ranks.keys()),list(ranks.values()))\n",
    "            df_ranks.to_pickle(f\"Data/{pep}/label_dict.pkl\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {pep} not found\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves some meta data of all users\n",
    "def prepare_user_inf(peps):\n",
    "    df = pd.DataFrame(columns = [\"length\",\"cluster\"])\n",
    "    for pep in peps:\n",
    "        try:\n",
    "            with open(f\"Data/{pep}/final_series.json\") as json_file:\n",
    "                data_path = json.load(json_file)\n",
    "            with open(f\"Data/labels_infomap_corr03.json\") as json_file:\n",
    "                data_cluster = json.load(json_file)\n",
    "                \n",
    "            df.loc[pep] = [len(data_path), data_cluster[str(pep)]]\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {pep} not found\")\n",
    "    #return df\n",
    "    df.to_pickle(\"data_inf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 78 not found\n",
      "File 417 not found\n",
      "File 710 not found\n",
      "File 727 not found\n",
      "File 732 not found\n",
      "File 782 not found\n",
      "File 791 not found\n",
      "File 795 not found\n",
      "File 821 not found\n",
      "File 841 not found\n",
      "File 846 not found\n",
      "File 852 not found\n",
      "File 853 not found\n",
      "File 854 not found\n",
      "File 855 not found\n"
     ]
    }
   ],
   "source": [
    "prepare_user_inf(range(856))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 78 not found\n",
      "File 417 not found\n",
      "File 710 not found\n",
      "File 727 not found\n",
      "File 732 not found\n",
      "File 782 not found\n",
      "File 791 not found\n",
      "File 795 not found\n",
      "File 821 not found\n",
      "File 841 not found\n",
      "File 846 not found\n",
      "File 852 not found\n",
      "File 853 not found\n",
      "File 854 not found\n",
      "File 855 not found\n"
     ]
    }
   ],
   "source": [
    "prepare_data(range(856))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_loc(peps):\n",
    "    locs = np.array([[],[]])\n",
    "    for pep in peps:\n",
    "        #import pdb; pdb.set_trace()  \n",
    "        try:\n",
    "            with open(f\"Data_m_loc/{pep}/stop_coords.json\") as json_file:\n",
    "                data_loc = np.array(json.load(json_file))[:20].transpose()\n",
    "            #import pdb; pdb.set_trace()\n",
    "            locs = np.concatenate((locs,data_loc),axis=1)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {pep} not found\")\n",
    "            continue  \n",
    "        dict_lat_lon = {'lat':locs[0],'lon':locs[1]}\n",
    "    return dict_lat_lon\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
